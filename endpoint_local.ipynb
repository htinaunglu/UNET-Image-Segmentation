{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97571bc",
   "metadata": {},
   "source": [
    "## Inference Script\n",
    "As Sagemaker endpoint is not working at the moment, I use the script to predict the images in the notebook.\n",
    "**Note: Please Train the model first, download it and extract it to use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61fc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import tqdm\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "JSON_CONTENT_TYPE = 'application/json'\n",
    "JPEG_CONTENT_TYPE = 'image/jpeg'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dcaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bc4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 1, features = [64, 128, 256, 512],):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature * 2, feature, kernel_size= 2, stride = 2,\n",
    "                )\n",
    "            ) \n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "            \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "            \n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size= 1)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        # reverse the skipconnection list\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            if x.shape != skip_connection.shape:\n",
    "                # take out the width and heigh of neuron, we use only channel\n",
    "                # eg. 161 x 161 -> output: 160 x 160 (we can't pooling for edges)\n",
    "                x = TF.resize(x, size= skip_connection.shape[2:]) \n",
    "            \n",
    "            concat_skip = torch.cat((skip_connection, x), dim = 1)\n",
    "            x = self.ups[idx+ 1](concat_skip)\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da61c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    print(\"In model_fn. Model directory is -\")\n",
    "    print(model_dir)\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "    \n",
    "    with open(\"./model.pth\", \"rb\") as f: #your model path and name\n",
    "        print(\"Loading the U-NET model\")\n",
    "        checkpoint = torch.load(f)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print('MODEL-LOADED')\n",
    "        logger.info('model loaded successfully')\n",
    "    #model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77dfd7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(request_body, content_type=JPEG_CONTENT_TYPE):\n",
    "    logger.info('Deserializing the input data.')\n",
    "    logger.debug(f'Request body CONTENT-TYPE is: {content_type}')\n",
    "    logger.debug(f'Request body TYPE is: {type(request_body)}')\n",
    "    if content_type == JPEG_CONTENT_TYPE: \n",
    "        return Image.open(io.BytesIO(request_body))\n",
    "    logger.debug('loded JPEG content')\n",
    "    # process a URL submitted to the endpoint\n",
    "    \n",
    "    raise Exception('Requested unsupported ContentType in content_type: {}'.format(content_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8645620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(input_object, model):\n",
    "    \n",
    "    logger.info('In predict fn')\n",
    "    test_transform = transforms.Compose([transforms.Resize((160, 240)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.0, 0.0, 0.0],\n",
    "                                                              std=[1.0, 1.0, 1.0])])\n",
    "                                                              #max_pixel_value=255.0,\n",
    "    logger.info(\"transforming input\")\n",
    "    input_object=test_transform(input_object) #1st error with Image # Solved\n",
    "    input_object = input_object.cuda() #put data into GPU\n",
    "    with torch.no_grad():\n",
    "        input_object = input_object.unsqueeze(0)\n",
    "        logger.info(\"Calling model\")\n",
    "        preds = torch.sigmoid(model(input_object)) #2nd error \n",
    "        preds = (preds > 0.5).float()\n",
    "        prediction = preds\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model_dir = \"./model.pth\" # Model path and name\n",
    "    model = model_fn(model_dir)\n",
    "    image_folder = \"./test\" # test image folder\n",
    "    saved_folder = \"./result_imgs/\" #prediction result folder\n",
    "    if not os.path.exists(saved_folder):\n",
    "        os.makedirs(saved_folder)\n",
    "    count = os.listdir(image_folder)\n",
    "    for i in tqdm(range(len(count)-1)):\n",
    "        img_name = count[i]\n",
    "        with open(os.path.join(image_folder, img_name),\"rb\") as myimg:\n",
    "            payload = myimg.read() \n",
    "        imgf = input_fn(payload, content_type=JPEG_CONTENT_TYPE)\n",
    "        prediction = predict_fn(imgf, model)\n",
    "        torchvision.utils.save_image(\n",
    "        prediction,  saved_folder + img_name[:-3] + \"_mask.png\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
